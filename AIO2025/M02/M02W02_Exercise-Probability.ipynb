{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Subjective test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    \"\"\"Create the training dataset for tennis prediction.\"\"\"\n",
    "    data = [[\"Sunny\",    \"Hot\",  \"High\",   \"Weak\",   \"No\"],\n",
    "            [\"Sunny\",    \"Hot\",  \"High\",   \"Strong\", \"No\"],\n",
    "            [\"Overcast\", \"Hot\",  \"High\",   \"Weak\",   \"Yes\"],\n",
    "            [\"Rain\",     \"Mild\", \"High\",   \"Weak\",   \"Yes\"],\n",
    "            [\"Rain\",     \"Cool\", \"Normal\", \"Weak\",   \"Yes\"],\n",
    "            [\"Rain\",     \"Cool\", \"Normal\", \"Strong\", \"No\"],\n",
    "            [\"Overcast\", \"Cool\", \"Normal\", \"Strong\", \"Yes\"],\n",
    "            [\"Overcast\", \"Mild\", \"High\",   \"Weak\",   \"No\"],\n",
    "            [\"Sunny\",    \"Cool\", \"Normal\", \"Weak\",   \"Yes\"],\n",
    "            [\"Rain\",     \"Mild\", \"Normal\", \"Weak\",   \"Yes\"]]\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Sunny' 'Hot' 'High' 'Weak' 'No']\n",
      " ['Sunny' 'Hot' 'High' 'Strong' 'No']\n",
      " ['Overcast' 'Hot' 'High' 'Weak' 'Yes']\n",
      " ['Rain' 'Mild' 'High' 'Weak' 'Yes']\n",
      " ['Rain' 'Cool' 'Normal' 'Weak' 'Yes']\n",
      " ['Rain' 'Cool' 'Normal' 'Strong' 'No']\n",
      " ['Overcast' 'Cool' 'Normal' 'Strong' 'Yes']\n",
      " ['Overcast' 'Mild' 'High' 'Weak' 'No']\n",
      " ['Sunny' 'Cool' 'Normal' 'Weak' 'Yes']\n",
      " ['Rain' 'Mild' 'Normal' 'Weak' 'Yes']]\n"
     ]
    }
   ],
   "source": [
    "train_data = create_training_data()\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute prior probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prior_probabilities(train_data):\n",
    "    \"\"\"\n",
    "    Calculate prior probabilities P(Play Tennis = Yes/No).\n",
    "    Args:\n",
    "        train_data: Training dataset\n",
    "    Returns:\n",
    "        Array of prior probabilities [P(No), P(Yes)]\n",
    "    \"\"\"\n",
    "    class_names = [\"No\", \"Yes\"]\n",
    "    total_samples = len(train_data[:,-1])#final output\n",
    "    prior_probs = np.zeros(len(class_names))\n",
    "\n",
    "    prior_probs[1] = np.sum(np.where(train_data[:,-1] == \"Yes\",1, 0)) / total_samples\n",
    "    prior_probs[0] = np.sum(np.where(train_data[:,-1] == \"No\",1, 0)) / total_samples\n",
    "\n",
    "    return prior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(‘Play Tennis’ = No) 0.4\n",
      "P(‘Play Tennis’ = Yes) 0.6\n"
     ]
    }
   ],
   "source": [
    "prior_probability = compute_prior_probabilities(train_data=train_data)\n",
    "print(\"P(‘Play Tennis’ = No)\", prior_probability[0])\n",
    "print(\"P(‘Play Tennis’ = Yes)\", prior_probability[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute conditional probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_conditional_probabilities(train_data):\n",
    "    \"\"\"\n",
    "    Calculate conditional probabilities P(Feature|Class) for all features.\n",
    "    Args:\n",
    "        train_data: Training dataset (numpy array with features and target column)\n",
    "    Returns:\n",
    "        Tuple of (conditional_probabilities, feature_values)\n",
    "    \"\"\"\n",
    "    class_names = [\"No\", \"Yes\"]\n",
    "    y_train = train_data[:, -1]\n",
    "    n_features = train_data.shape[1] - 1  # Exclude target column\n",
    "    conditional_probs = []\n",
    "    feature_values = []\n",
    "\n",
    "    for feature_idx in range(n_features):\n",
    "        # Get unique values for this feature\n",
    "        unique_values = np.unique(train_data[:, feature_idx])\n",
    "        feature_values.append(unique_values)\n",
    "\n",
    "        # Initialize conditional probability matrix\n",
    "        # Shape: (number of classes, number of unique feature values)\n",
    "        feature_cond_probs = np.zeros((len(class_names), len(unique_values)))\n",
    "\n",
    "        for class_idx, class_name in enumerate(class_names):\n",
    "            # Get samples for this class\n",
    "            class_data = train_data[y_train == class_name]\n",
    "            class_count = len(class_data)\n",
    "\n",
    "            for value_idx, value_name in enumerate(unique_values):\n",
    "                # Count occurrences of this feature value in this class\n",
    "                value_count_in_class = np.sum(class_data[:, feature_idx] == value_name)\n",
    "\n",
    "                # Calculate conditional probability with Laplace smoothing\n",
    "                # P(Feature=value|Class=class) = Count(value & class) / Count(class)\n",
    "                denominator = class_count\n",
    "                cond_prob = value_count_in_class / denominator\n",
    "\n",
    "                # Store the probability\n",
    "                feature_cond_probs[class_idx, value_idx] = cond_prob\n",
    "                # print(f\"class_idx = {class_idx}, class_name = {class_name}\")\n",
    "                # print(f\"cond_prob = {cond_prob}\")\n",
    "\n",
    "        conditional_probs.append(feature_cond_probs)\n",
    "        # print(\"feature_cond_probs = \",feature_cond_probs)\n",
    "\n",
    "    return conditional_probs, feature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 =  ['Overcast' 'Rain' 'Sunny']\n",
      "x2 =  ['Cool' 'Hot' 'Mild']\n",
      "x3 =  ['High' 'Normal']\n",
      "x4 =  ['Strong' 'Weak']\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "_, feature_values = compute_conditional_probabilities(train_data=train_data)\n",
    "print(\"x1 = \",feature_values[0])\n",
    "print(\"x2 = \",feature_values[1])\n",
    "print(\"x3 = \",feature_values[2])\n",
    "print(\"x4 = \",feature_values[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get feature index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_index(feature_value, feature_values):\n",
    "    \"\"\"\n",
    "    Get the index of a feature value in the feature values array.\n",
    "    Args:\n",
    "        feature_value: Value to find\n",
    "        feature_values: Array of possible feature values\n",
    "    Returns:\n",
    "       Index of the feature value\n",
    "    \"\"\"\n",
    "    return np.where(feature_values == feature_value)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2\n"
     ]
    }
   ],
   "source": [
    "_, feature_values = compute_conditional_probabilities(train_data)\n",
    "outlook = feature_values[0]\n",
    "i1 = get_feature_index(\"Overcast\", outlook)\n",
    "i2 = get_feature_index(\"Rain\", outlook)\n",
    "i3 = get_feature_index(\"Sunny\", outlook)\n",
    "\n",
    "print(i1, i2, i3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train naive bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(train_data):\n",
    "    \"\"\"\n",
    "    Train the Naive Bayes classifier.\n",
    "    Args:\n",
    "        train_data: Training dataset\n",
    "    Returns:\n",
    "        Tuple of (prior_probabilities, conditional_probabilities, feature_names)\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate prior probabilities\n",
    "    prior_probabilities = compute_prior_probabilities(train_data)\n",
    "\n",
    "    # Calculate conditional probabilities\n",
    "    conditional_probabilities, feature_names = compute_conditional_probabilities(train_data)\n",
    "\n",
    "    return prior_probabilities, conditional_probabilities, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "prior_probs, conditional_probs, feature_names = train_naive_bayes(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "odxm81_ozpNi"
   },
   "outputs": [],
   "source": [
    "def predict_play_tennis(\n",
    "        X, prior_probabilities, conditional_probabilities, feature_names\n",
    "):\n",
    "    \"\"\"\n",
    "    Make a prediction for given features.\n",
    "\n",
    "    Args:\n",
    "        X: List of feature values [Outlook, Temperature, Humidity, Wind]\n",
    "        prior_probabilities: Prior probabilities for each class\n",
    "        condtional_probabilities: Conditional probabilities for each feature\n",
    "        feature_names: Names/values for each features\n",
    "    Returns:\n",
    "        Tuple of (prediction, probabilities)\n",
    "    \"\"\"\n",
    "    class_names = [\"No\", \"Yes\"]\n",
    "\n",
    "    # Get feature indices\n",
    "    feature_indices = []\n",
    "    for i, feature_value in enumerate(X):\n",
    "        feature_indices.append(get_feature_index(feature_value, feature_names[i]))\n",
    "\n",
    "    # Calculate probabilities for each class\n",
    "    class_probabilities = []\n",
    "\n",
    "    for class_idx in range(len(class_names)):\n",
    "        # Start with prior probability\n",
    "        prob = prior_probabilities[class_idx]\n",
    "\n",
    "        # Multiply by conditional probabilities\n",
    "        for feature_idx, value_idx in enumerate(feature_indices):\n",
    "            prob *= conditional_probabilities[feature_idx][class_idx, value_idx]\n",
    "\n",
    "        class_probabilities.append(prob)\n",
    "\n",
    "\n",
    "    # Normalize probabilities\n",
    "    total_prob = sum(class_probabilities)\n",
    "    if total_prob > 0:\n",
    "        normalized_probs = [p / total_prob for p in class_probabilities]\n",
    "    else:\n",
    "        normalized_probs = [0.5, 0.5] # Default if all probabilites are 0\n",
    "\n",
    "    # Make prediction\n",
    "    predicted_class_idx = np.argmax(class_probabilities)\n",
    "    prediction = class_names[predicted_class_idx]\n",
    "\n",
    "    # Create probability dictionary\n",
    "    prob_dict = {\n",
    "        \"No\": round(normalized_probs[0].item(), 2),\n",
    "        \"Yes\": round(normalized_probs[1].item(), 2)\n",
    "    }\n",
    "\n",
    "    return prediction, prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad should not go!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('No', {'No': 0.87, 'Yes': 0.13})"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [\"Sunny\",\"Cool\", \"High\", \"Strong\"]\n",
    "\n",
    "prior_probs, conditional_probs, feature_names = train_naive_bayes(train_data)\n",
    "prediction, prob_dict = predict_play_tennis(\n",
    "    X, prior_probs, conditional_probs, feature_names\n",
    ")\n",
    "\n",
    "if  prediction == \"Yes\":\n",
    "    print(\"Ad should go!\")\n",
    "else:\n",
    "    print(\"Ad should not go!\")\n",
    "\n",
    "prediction, prob_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Objective test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification - Play Tennis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 A P(\"Play Tennis\" = \"Yes\") = 6/10, P(\"Play Tennis\" = \"No\") = 4/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need more help!!!!!\n",
    "#2 B P(\"Play Tennis\" = \"Yes\"|X) ∝ 0.0028\n",
    "#3 C P(\"Play Tennis\" = \"No\"| X) ∝ 0.0188\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(\"Play Tennis\" = \"no\" | X) = 0.8710 (87.10%)\n",
      "P(\"Play Tennis\" = \"yes\" | X) = 0.1290 (12.90%)\n"
     ]
    }
   ],
   "source": [
    "X = [\"Sunny\",\"Cool\", \"High\", \"Strong\"]\n",
    "prior_probs, conditional_probs, feature_names = train_naive_bayes(train_data)\n",
    "final_probabilities, prediction = predict(X, prior_probs, conditional_probs, feature_names)\n",
    "print(f\"P(\\\"Play Tennis\\\" = \\\"no\\\" | X) = {final_probabilities[0]:.4f} ({final_probabilities[0]*100:.2f}%)\")\n",
    "print(f\"P(\\\"Play Tennis\\\" = \\\"yes\\\" | X) = {final_probabilities[1]:.4f} ({final_probabilities[1]*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 B\n",
    "#5 A\n",
    "#6 B\n",
    "#7 C\n",
    "#8 A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label Classification - Traffic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need more help!!!!!\n",
    "# 9\n",
    "# 10\n",
    "# 11\n",
    "# 12\n",
    "# 13\n",
    "# 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need more help!!!!!\n",
    "# 15\n",
    "# 16\n",
    "# 17"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
